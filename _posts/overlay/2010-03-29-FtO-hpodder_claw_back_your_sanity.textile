---
layout: post
title: hpodder - Claw back your sanity
description: Command line podcatching client
categories: [cli, feeds, fto, haskell, hpodder, podcast]
---

In what I hope will be the first in a new series of posts here I want to discuss a package from "my overlay":http://github.com/JNRowe/misc-overlay.

The package for today is the wonderful "hpodder":http://software.complete.org/hpodder, a command line podcatcher written by "John Goerzen":http://changelog.complete.org/. @hpodder@ is written in "haskell":http://www.haskell.org/, and beyond "ghc":http://www.haskell.org/ghc/ it also requires a few other haskell packages.  Gentoo users can grab an ebuild from "github":http://github.com/JNRowe/misc-overlay/blob/master/media-sound/hpodder/hpodder-1.1.5.ebuild, or simply "use my overlay":http://github.com/JNRowe/misc-overlay/blob/master/README.rst to avoid having to pull the individual ebuilds.

h3. Installation and setup

If you haven't already installed @ghc@ you may wish to consider installing the binary version with @USE=binary@, as @ghc@ can take a long time to build.

{% highlight text %}
# su -
# echo dev-lang/ghc build >>/etc/portage/package.use
# emerge hpodder
# exit
$ hpodder
{% endhighlight %}

On initial run @hpodder@ will ask where it should store downloaded podcasts, and offer to subscribe to some sample feeds.  Unless you really have no idea what podcasts you'd like to download I'd suggest skipping the samples and adding your own feeds straight away:

h3. Usage

{% highlight text %}
$ hpodder add http://downloads.bbc.co.uk/podcasts/worldservice/scia/rss.xml
$ hpodder fetch
{% endhighlight %}

After issuing these two commands you'll have registered the BBC "Science in Action":None podcast and downloaded the episodes referenced in the feed to @~/podcasts@(or whichever location you specified when configuring @hpodder@).

If you're switching from another podcast client then you'll likely want to ignore all the old episodes in your feeds to avoid downloading them again, thankfully @hpodder@ has a command for just that purpose:

{% highlight text %}
$ hpodder catchup all
{% endhighlight %}

You can also specify one or more identification numbers instead of @all@ to mark only certain feeds as already downloaded, use @hpodder lscasts@ to see the identification numbers.  By default @catchup@ skips all but the last episode in the feed, but you can change that behaviour with the @-n@ option, see @hpodder catchup --help@ for details.

Once you've added your favourite feeds running @hpodder fetch@ at any time will re-fetch the feeds and download any new items.  If you wish to check which episodes will be downloaded you can update the feeds and check for pending episodes before downloading them:

{% highlight text %}
$ hpodder update
$ hpodder lscasts | grep Pend
$ hpodder download
{% endhighlight %}

If you see an episode you'd prefer not to download you can mark it as skipped:

{% highlight text %}
hpodder setstatus -c 1 -s Skipped 3
{% endhighlight %}

where the argument to @-c@ is a feed ID and the final argument is the episode number as shown in the @lscasts@ output.  There are various episode statuses that can be set see @hpodder setstatus --help@ for details.

That is basically all there is to it, @hpodder@ really is that simple!

h3. Bonus

I like to keep configuration data under version control, as I've mentioned here a number of times before.  The list of feeds I've subscribed to is valuable to me, but I don't care much for keeping the entire database in @~/.hpodder/hpodder.db@ backed up.  As @hpodder@ uses a simple "sqlite":http://www.sqlite.org/ database we can easily dump the entire thing as text or just the parts which are important to us.

I use "make":http://www.gnu.org/software/make/make.html to handle repetitive tasks as I've "explained in the past":/2009/10/11/TaD-Making_a_nice_home.html.  And for dumping my subscription list I use the following @make@ snippet:

{% highlight make %}
hpodder.db.txt: hpodder.db
	$(info - Dumping hpodder podcasts list)
	sqlite3 $< 'SELECT feedurl FROM podcasts' >$@
{% endhighlight %}
p>. "Fork this code":http://gist.github.com/350683

It uses the command line @sqlite@ client to select just the feed URLs from the database and dump them to a file.  The simple text output it produces is perfect for storing under version control for backup, or feeding back to @hpodder@ should the worst happen.

